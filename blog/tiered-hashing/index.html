<!doctypehtml><html prefix="og: http://ogp.me/ns#"lang=en_US><meta charset=utf-8><meta content=width=device-width,initial-scale=1 name=viewport><title>Tiered hashing: fast generative hash functions | purplesyringa's blog</title><link href=../../favicon.ico?v=2 rel=icon><link href=../../all.css rel=stylesheet><link href=../../blog.css rel=stylesheet><link href=../../vendor/Temml-Local.css rel=stylesheet><link crossorigin href=https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100..900;1,100..900&family=Roboto+Mono:ital,wght@0,100..700;1,100..700&family=Roboto:ital,wght@0,400;0,700;1,400;1,700&family=Slabo+27px&display=swap rel=stylesheet><link href=../../fonts/webfont.css rel=stylesheet><link media="screen and (prefers-color-scheme: dark"href=../../vendor/atom-one-dark.min.css rel=stylesheet><link media="screen and (prefers-color-scheme: light"href=../../vendor/a11y-light.min.css rel=stylesheet><link title="Blog posts"href=../../blog/feed.rss rel=alternate type=application/rss+xml><meta content="Tiered hashing: fast generative hash functions"property=og:title><meta content=article property=og:type><meta content=https://purplesyringa.moe/blog/tiered-hashing/og.png property=og:image><meta content=https://purplesyringa.moe/blog/tiered-hashing/ property=og:url><meta property=og:description><meta content=en_US property=og:locale><meta content="purplesyringa's blog"property=og:site_name><meta content=summary_large_image name=twitter:card><meta content=https://purplesyringa.moe/blog/tiered-hashing/og.png name=twitter:image><script data-website-id=0da1961d-43f2-45cc-a8e2-75679eefbb69 defer src=https://zond.tei.su/script.js></script><body><header><div class=viewport-container><div class=media><a href=https://github.com/purplesyringa><img alt=GitHub src=../../images/github-mark-white.svg></a></div><h1><a href=/>purplesyringa</a></h1><nav><a href=../..>about</a><a class=current href=../../blog/>blog</a><a href=../../sink/>kitchen sink</a></nav></div></header><section><div class=viewport-container><h2>Tiered hashing: fast generative hash functions</h2><time>November 25, 2024</time><p>There is a constant call for faster hash tables. Many non-cryptographic hash functions attempt to resolve this, but their performance is sometimes insufficient.<p>In these cases, faster hash functions are typically designed by hand, tuned to specific data – quite a time-consuming process. I have developed the <a href=https://lib.rs/tiered-hash>tiered-hash</a> crate to automatically generate fast hash functions trained on a dataset of keys, usable for hash tables.<p>The hash function can either be generated in runtime for dynamic data (with JIT compilation) or in compile time for static data. Non-default instruction sets (such as SSE3 on x86-64) can be enabled either automatically (when using JIT) or manually (when using AOT).<p class=next-group><span aria-level=3 class=side-header role=heading><span>Limitations</span></span>As <code>tiered-hash</code> trains on a specific dataset, it might behave significantly worse on a different dataset. In other words, <em>dynamic</em> hash tables based on <code>tiered-hash</code> are <em>not</em> DoS-resistant, by design. This is not a problem for static hash tables that are only built once, but dynamic hash tables need guard rails to switch to another hash function if collision rate increases unexpectedly.<p><code>tiered-hash</code> is a tradeoff between construction time and access time. Hash functions are slower to construct than typically, though still fast enough for certain applications.<p><code>tiered-hash</code> does not provide <em>any</em> security guarantees beyond a good collision rate on the dataset it was trained on.<p>The hash function generation is parametric, meaning that it has to be redone when the hash table parameters change.<h2>Architecture</h2><p class=next-group><span aria-level=3 class=side-header role=heading><span>Output</span></span>Most general-purpose hash functions output a pseudo-random <eq><math><mi>N</mi></math></eq>-bit number <eq><math><mi>h</mi></math></eq>, which are then split into smaller individual hashes <eq><math><mrow><mo form=prefix stretchy=false>(</mo><msub><mi>h</mi><mn>1</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>h</mi><mi>k</mi></msub><mo form=postfix stretchy=false>)</mo></mrow></math></eq> by the hash table. The hash table then typically assumes the <eq><math><msub><mi>h</mi><mi>i</mi></msub></math></eq> are uniform over <eq><math><mrow><mo form=prefix stretchy=false>[</mo><mn>0</mn><mo separator=true>;</mo><msub><mi>n</mi><mi>i</mi></msub><mo form=postfix stretchy=false>)</mo></mrow></math></eq> (and sometimes independent), and uses them directly for indices, steps, and tags.<p>For example, in separate chaining <eq><math><msub><mi>h</mi><mn>1</mn></msub></math></eq> is used as the bucket index, while a fixed-length tag <eq><math><msub><mi>h</mi><mn>2</mn></msub></math></eq> may be used for SIMD optimization, much like in SwissTable. For bucket-based PHFs, <eq><math><msub><mi>h</mi><mn>1</mn></msub></math></eq> and <eq><math><msub><mi>h</mi><mn>2</mn></msub></math></eq> are used for an individual position contribution and the bucket index, respectively. For open addressing with double hashing, <eq><math><msub><mi>h</mi><mn>1</mn></msub></math></eq> and <eq><math><msub><mi>h</mi><mn>2</mn></msub></math></eq> can be used as the initial probe index and the step (minus one). For linear probing, stronger guarantees are necessary to reliably prevent primary clustering; we’ll handle that later.<p>Ensuring that the hash is high-quality for any choice of the splitting algorithm is complicated. Instead, our hashes output <eq><math><mrow><mo form=prefix stretchy=false>(</mo><msub><mi>h</mi><mn>1</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>h</mi><mi>k</mi></msub><mo form=postfix stretchy=false>)</mo></mrow></math></eq> directly instead of leaving the post-processing step to the hash table implementation.<p class=next-group><span aria-level=3 class=side-header role=heading><span>Tiers</span></span>As realistic inputs often contain easily extractable entropy, we can often cut corners by not using a high-quality method for producing <eq><math><mi>h</mi></math></eq>, as long as it doesn’t lead to problems on the training set.<p>We thus process the hashing methods in order of tiers. The word “tier” comes from tiered JIT compilation, where compilers of different tiers provide faster code at expense of compilation time. The first hash function of sufficient quality is returned, with a fallback to further tiers if the function is ruled unusable for some reason.<p class=next-group><span aria-level=3 class=side-header role=heading><span>Quality</span></span>To check whether a certain hash is of sufficient quality, we analyze the number of collisions of <em>and across</em> <eq><math><msub><mi>h</mi><mi>i</mi></msub></math></eq>. (Again, ignore linear probing for now.)<p>In particular, we’ll analyze the collision rate in certain subtuples <eq><math><mrow><mo form=prefix stretchy=false>{</mo><msub><mi>h</mi><mi>i</mi></msub><msub><mo form=postfix stretchy=false>}</mo><mrow><mi>i</mi><mo>∈</mo><msub><mi>A</mi><mi>j</mi></msub></mrow></msub></mrow></math></eq> of hashes. Analyzing subsets is necessary because even if both <eq><math><msub><mi>h</mi><msub><mi>i</mi><mn>1</mn></msub></msub></math></eq> and <eq><math><msub><mi>h</mi><msub><mi>i</mi><mn>2</mn></msub></msub></math></eq> have few collisions, they might be correlated, so using them together does not necessarily decrease the collision rate multiplicatively.<p>Denoting by <eq><math><msub><mi>H</mi><mi>j</mi></msub></math></eq> the hashes in <eq><math><msub><mi>A</mi><mi>j</mi></msub></math></eq> mapped bijectively into a range <eq><math><mrow><mo form=prefix stretchy=false>[</mo><mn>0</mn><mo separator=true>;</mo><msub><mi>N</mi><mi>j</mi></msub><mo>=</mo><msub><mo movablelimits=false>∏</mo><mrow><mi>i</mi><mo>∈</mo><msub><mi>A</mi><mi>j</mi></msub></mrow></msub><msub><mi>n</mi><mi>i</mi></msub><mo form=postfix stretchy=false>)</mo></mrow></math></eq>, we’re interested in the collision rate of <eq><math><mrow><msub><mi>H</mi><mi>j</mi></msub><mo form=prefix stretchy=false>(</mo><mi>x</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq> among the elements <eq><math><mrow><mi>x</mi><mo>∈</mo></mrow><mrow><mi>X</mi></mrow></math></eq> of the training set.<p>We could simply use a generic hash map to track the number of occurences of different <eq><math><msub><mi>H</mi><mi>j</mi></msub></math></eq>s, but it turns out that there’s a more efficient way. The core of our approach is that at some point during testing, we stumble upon a hash <eq><math><msub><mi>H</mi><msup><mi>j</mi><mo class=tml-prime lspace=0em rspace=0em>′</mo></msup></msub></math></eq> of known good quality, which lets us remove the hashing step from the generic hash map.<p>We will perform the quality test in order of increasing <eq><math><msub><mi>N</mi><mi>j</mi></msub></math></eq>. If a certain <eq><math><mi>j</mi></math></eq> fails the test, we stop.<p>If <eq><math><mrow><msub><mi>N</mi><mi>j</mi></msub><mo>⪅</mo></mrow><mrow><mi>|</mi><mi>X</mi><mi>|</mi></mrow></math></eq>, we can test <eq><math><msub><mi>H</mi><mi>j</mi></msub></math></eq> for collisions by using an array of size <eq><math><msub><mi>N</mi><mi>j</mi></msub></math></eq> as a histogram and filling it from <eq><math><mi>X</mi></math></eq>, tracking the number of encountered collisions. This takes <eq><math><mrow><mrow><mi mathvariant=normal>Θ</mi></mrow><mo form=prefix stretchy=false>(</mo><msub><mi>N</mi><mi>j</mi></msub><mo>+</mo><mi>|</mi><mi>X</mi><mi>|</mi><mo form=postfix stretchy=false>)</mo><mo>=</mo></mrow><mrow><mrow><mi mathvariant=normal>Θ</mi></mrow><mo form=prefix stretchy=false>(</mo><mi>|</mi><mi>X</mi><mi>|</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq> time.<p>Otherwise, suppose <eq><math><mrow><msub><mi>N</mi><mi>j</mi></msub><mo>≫</mo></mrow><mrow><mi>|</mi><mi>X</mi><mi>|</mi></mrow></math></eq>. <em>For all practical hash tables</em>, there exists a subset <eq><math><mrow><msub><mi>A</mi><msup><mi>j</mi><mo class=tml-prime lspace=0em rspace=0em>′</mo></msup></msub><mo>⊂</mo></mrow><mrow><msub><mi>A</mi><mi>j</mi></msub></mrow></math></eq> such that <eq><math><mrow><msub><mi>N</mi><msup><mi>j</mi><mo class=tml-prime lspace=0em rspace=0em>′</mo></msup></msub><mo>≈</mo></mrow><mrow><mi>|</mi><mi>X</mi><mi>|</mi></mrow></math></eq>. In simpler terms, if a hash table uses a large combination of hashes, it must also use one of its hash-table-sized subsets. This is quite intuitive: SwissTable, for instance, is interested in the collision rate of <eq><math><mrow><mo form=prefix stretchy=false>(</mo><mrow><mtext></mtext><mi>Bucket</mi></mrow><mo separator=true>,</mo><mrow><mtext></mtext><mi>Tag</mi></mrow><mo form=postfix stretchy=false>)</mo></mrow></math></eq>, which is larger than the table itself, but it’s also interested in the collision rate of <eq><math><mrow><mtext></mtext><mi>Bucket</mi></mrow></math></eq>, which exactly spans the table.<p>What this means is that we can replace the array of size <eq><math><msub><mi>N</mi><mi>j</mi></msub></math></eq> with a hash table that uses <eq><math><msub><mi>H</mi><msup><mi>j</mi><mo class=tml-prime lspace=0em rspace=0em>′</mo></msup></msub></math></eq> as the key. As <eq><math><msub><mi>H</mi><msup><mi>j</mi><mo class=tml-prime lspace=0em rspace=0em>′</mo></msup></msub></math></eq> passed the test, it has a low collision rate, and as <eq><math><mrow><msub><mi>N</mi><msup><mi>j</mi><mo class=tml-prime lspace=0em rspace=0em>′</mo></msup></msub><mo>≈</mo></mrow><mrow><mi>|</mi><mi>X</mi><mi>|</mi></mrow></math></eq>, this makes it is a good hash for a table containing <eq><math><mrow><mi>|</mi><mi>X</mi><mi>|</mi></mrow></math></eq> elements. Therefore, filling the table from <eq><math><mi>X</mi></math></eq> with this hash takes <eq><math><mrow><mrow><mi mathvariant=normal>Θ</mi></mrow><mo form=prefix stretchy=false>(</mo><mi>|</mi><mi>X</mi><mi>|</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq> time, and after that’s done, we can count the collisions of <eq><math><msub><mi>H</mi><mi>j</mi></msub></math></eq> in each bucket individually. We can do this in quadratic time of the bucket size, which will be performant, as the expected bucket size is just <eq><math><mrow><mrow><mi mathvariant=normal>Θ</mi></mrow><mo form=prefix stretchy=false>(</mo><mn>1</mn><mo form=postfix stretchy=false>)</mo></mrow></math></eq>. In total, the algorithm takes <eq><math><mrow><mrow><mi mathvariant=normal>Θ</mi></mrow><mo form=prefix stretchy=false>(</mo><mi>|</mi><mi>X</mi><mi>|</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq> time.<h2>Hashing data</h2><p class=next-group><span aria-level=3 class=side-header role=heading><span>Groups</span></span>Often, we need to hash short data whose properties can be analyzed in reasonable time. Suppose for a moment that we have a slowish but generic way to hash a vector of <eq><math><mi>N</mi></math></eq>-bit words into one <eq><math><mi>N</mi></math></eq>-bit word, and our goal is to reduce the workload (i.e. input length) of this algorithm.<p>Firstly, we note that we don’t have to produce <eq><math><mrow><msub><mi>h</mi><mn>1</mn></msub><mo separator=true>,</mo></mrow><mrow><mo>…</mo></mrow><mrow><mo separator=true>,</mo></mrow><mrow><msub><mi>h</mi><mi>n</mi></msub></mrow></math></eq> from one <eq><math><mi>N</mi></math></eq>-bit hash. Instead, we can split the input words into several groups, hash each group individually, and extract each <eq><math><msub><mi>h</mi><mi>i</mi></msub></math></eq> from one of the groups. Of course, some words may be dropped altogether if the other words suffice entropy-wise.<p>Note that the mapping from <eq><math><msub><mi>h</mi><mi>i</mi></msub></math></eq> to groups is not injective: for example, if <eq><math><msub><mi>h</mi><mn>1</mn></msub></math></eq> and <eq><math><msub><mi>h</mi><mn>2</mn></msub></math></eq> need to be independent, but the input contains just one word, we’ll have to extract them both from the hash of that word. Nevertheless, when such a split is possible, it allows several hashes to be computed independently in parallel, using the superscalar architecture of modern CPUs.<p>After computing the group hash <eq><math><mi>u</mi></math></eq>, we can extract <eq><math><mrow><msub><mi>h</mi><mn>1</mn></msub><mo separator=true>,</mo></mrow><mrow><mo>…</mo></mrow><mrow><mo separator=true>,</mo></mrow><mrow><msub><mi>h</mi><mi>k</mi></msub></mrow></math></eq> from <eq><math><mi>u</mi></math></eq> iteratively as follows:<section><eqn><math style="display:block math;"class=tml-display display=block><mtable columnalign="right left"displaystyle=true><mtr><mtd style="padding:0.7ex 0em 0.7ex 0em;"class=tml-right><msub><mi>u</mi><mn>1</mn></msub></mtd><mtd style="padding:0.7ex 0em 0.7ex 0em;"class=tml-left><mrow><mo>=</mo><mi>u</mi><mo separator=true>,</mo></mrow></mtd></mtr><mtr><mtd style="padding:0.7ex 0em 0.7ex 0em;"class=tml-right><msub><mi>h</mi><mi>i</mi></msub></mtd><mtd style="padding:0.7ex 0em 0.7ex 0em;"class=tml-left><mrow><mo>=</mo><msub><mi>u</mi><mi>i</mi></msub><msub><mi>n</mi><mi>i</mi></msub><mo lspace=0.1667em rspace=0.1667em><mi>d</mi><mi>i</mi><mi>v</mi></mo><msup><mn>2</mn><mi>N</mi></msup><mo separator=true>,</mo></mrow></mtd></mtr><mtr><mtd style="padding:0.7ex 0em 0.7ex 0em;"class=tml-right><msub><mi>u</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mtd><mtd style="padding:0.7ex 0em 0.7ex 0em;"class=tml-left><mrow><mo>=</mo><msub><mi>u</mi><mi>i</mi></msub><msub><mi>n</mi><mi>i</mi></msub><mo lspace=0.2222em rspace=0.2222em>mod</mo><msup><mn>2</mn><mi>N</mi></msup><mi>.</mi></mrow></mtd></mtr></mtable></math></eqn></section><p>For power-of-two <eq><math><msub><mi>n</mi><mi>i</mi></msub></math></eq>, we can either reuse this approach with multiplication optimized to shifts, or improve latency by simultaneously extracting bit groups from the bottom of <eq><math><mi>u</mi></math></eq>. This way, we extract entropy from two ends, reducing the likelyhood of correlation between power-of-two <eq><math><msub><mi>n</mi><mi>i</mi></msub></math></eq>s and non-power-of-two <eq><math><msub><mi>n</mi><mi>i</mi></msub></math></eq>s.<p class=next-group><span aria-level=3 class=side-header role=heading><span>General case</span></span>So what generic hash do we use? The kernel of our method is the mixing function<section><eqn><math style="display:block math;"class=tml-display display=block><mrow><mrow><mtext></mtext><mi>mum</mi></mrow><mo form=prefix stretchy=false>(</mo><mi>x</mi><mo separator=true>,</mo><mi>y</mi><mo form=postfix stretchy=false>)</mo><mo>=</mo><mo form=prefix stretchy=false>(</mo><mi>x</mi><mi>y</mi><mo lspace=0.2222em rspace=0.2222em>mod</mo><msup><mn>2</mn><mi>N</mi></msup><mo form=postfix stretchy=false>)</mo><mo>⊕︎</mo><mo form=prefix stretchy=false>(</mo><mi>x</mi><mi>y</mi><mo lspace=0.1667em rspace=0.1667em><mi>d</mi><mi>i</mi><mi>v</mi></mo><msup><mn>2</mn><mi>N</mi></msup><mo form=postfix stretchy=false>)</mo><mo separator=true>,</mo></mrow></math></eqn></section><p>called “multiply and mix” or “folded multiply”. Unlike typical multiplication, <eq><math><mrow><mtext></mtext><mi>mum</mi></mrow></math></eq> has full avalanche, meaning that no finalization step is necessary to make all bits usable and independent. As far as we are aware, deficiencies of this mixer have not been explored; possible DoS attacks nonwithstanding, this function works fine in practice and is used as a key component of <a href=https://github.com/wangyi-fudan/wyhash>wyhash</a>, among others.<p>On Alder Lake, <eq><math><mrow><mtext></mtext><mi>mum</mi></mrow></math></eq> has latency <eq><math><mn>5</mn></math></eq>, so absorbing input iteratively with <eq><math><mrow><mtext></mtext><mi>mum</mi></mrow></math></eq> is not an option for short data. Instead, we introduce a parallelizable hash<section><eqn><math style="display:block math;"class=tml-display display=block><mrow><mi>u</mi><mo form=prefix stretchy=false>(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo form=postfix stretchy=false>)</mo><mo>=</mo><mrow><munderover><mo movablelimits=false>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></munderover></mrow><mrow><mtext></mtext><mi>mum</mi></mrow><mo form=prefix stretchy=false>(</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>⊕︎</mo><msub><mi>a</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo separator=true>,</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>⊕︎</mo><msub><mi>a</mi><mrow><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo form=postfix stretchy=false>)</mo><mo></mo><mspace width=1em></mspace><mo form=prefix stretchy=false>(</mo><mrow><mtext></mtext><mi>mod</mi></mrow><mspace width=0.3333em></mspace><msup><mn>2</mn><mi>N</mi></msup><mo form=postfix stretchy=false>)</mo><mo separator=true>,</mo></mrow></math></eqn></section><p>where both inputs <eq><math><msub><mi>x</mi><mi>i</mi></msub></math></eq> and the output <eq><math><mi>u</mi></math></eq> are <eq><math><mi>N</mi></math></eq> bits long, and <eq><math><msub><mi>a</mi><mi>i</mi></msub></math></eq> are random <eq><math><mi>N</mi></math></eq>-bit values. To hash an odd number of words, we add <eq><math><mrow><mrow><mtext></mtext><mi>mum</mi></mrow><mo form=prefix stretchy=false>(</mo><msub><mi>a</mi><mrow><mn>2</mn><mi>k</mi></mrow></msub><mo separator=true>,</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>k</mi></mrow></msub><mo form=postfix stretchy=false>)</mo></mrow></math></eq> to <eq><math><mi>u</mi></math></eq>. The arbitrary choices of <eq><math><mo lspace=0em rspace=0em>⊕︎</mo></math></eq> vs <eq><math><mo lspace=0em rspace=0em>+</mo></math></eq> were made with a goal of minimizing linearity in both <eq><math><mrow><mi>ℤ</mi><mi>/</mi><mn>2</mn><mi>ℤ</mi></mrow></math></eq> and <eq><math><mrow><mi>ℤ</mi><mi>/</mi><msup><mn>2</mn><mn>64</mn></msup><mi>ℤ</mi></mrow></math></eq>.<p>This design is based on <a href=https://www.cs.ucdavis.edu/~rogaway/papers/umac-full.pdf>the universal NH family</a>, which computes<section><eqn><math style="display:block math;"class=tml-display display=block><mrow><mi>u</mi><mo form=prefix stretchy=false>(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo form=postfix stretchy=false>)</mo><mo>=</mo><mrow><munderover><mo movablelimits=false>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></munderover></mrow><mo form=prefix stretchy=false>(</mo><mo form=prefix stretchy=false>(</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>a</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo form=postfix stretchy=false>)</mo><mo lspace=0.2222em rspace=0.2222em>mod</mo><msup><mn>2</mn><mi>N</mi></msup><mo form=postfix stretchy=false>)</mo><mo form=prefix stretchy=false>(</mo><mo form=prefix stretchy=false>(</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>a</mi><mrow><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo form=postfix stretchy=false>)</mo><mo lspace=0.2222em rspace=0.2222em>mod</mo><msup><mn>2</mn><mi>N</mi></msup><mo form=postfix stretchy=false>)</mo><mo></mo><mspace width=1em></mspace><mo form=prefix stretchy=false>(</mo><mrow><mtext></mtext><mi>mod</mi></mrow><mspace width=0.3333em></mspace><msup><mn>2</mn><mrow><mn>2</mn><mi>N</mi></mrow></msup><mo form=postfix stretchy=false>)</mo></mrow></math></eqn></section><p>for random <em>odd</em> <eq><math><mrow><msub><mi>a</mi><mn>0</mn></msub><mo separator=true>,</mo></mrow><mrow><mo>…</mo></mrow><mrow><mo separator=true>,</mo></mrow><mrow><msub><mi>a</mi><mrow><mn>2</mn><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></math></eq> and adds <eq><math><mrow><msub><mi>a</mi><mrow><mn>2</mn><mi>k</mi></mrow></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>k</mi></mrow></msub></mrow></math></eq> for odd number of words. NH has a good proven bound on the collision rate, so as long as we believe that <eq><math><mrow><mtext></mtext><mi>mum</mi></mrow></math></eq> behaves “as well as” <eq><math><mrow><mn>2</mn><mi>N</mi></mrow></math></eq>-bit multiplication, our scheme is of high quality, too. As another point of comparison, if <eq><math><mo lspace=0em rspace=0em>+</mo></math></eq>/<eq><math><mo lspace=0em rspace=0em>⊕︎</mo></math></eq> and <eq><math><mrow><mtext></mtext><mi>mum</mi></mrow></math></eq> were replaced with addition and multiplication in <eq><math><mrow><mi>G</mi><mi>F</mi><mo form=prefix stretchy=false>(</mo><msup><mn>2</mn><mi>N</mi></msup><mo form=postfix stretchy=false>)</mo></mrow></math></eq>, respectively, the scheme would clearly be <eq><math><msup><mn>2</mn><mrow><mo lspace=0em rspace=0em>−</mo><mi>N</mi></mrow></msup></math></eq>-almost universal. To be clear, this is mostly speculation and it is unknown whether this scheme is almost universal, even though it seems to be so in practice. Real cryptanalysis is more than welcome.<p>On Alder Lake, <eq><math><mrow><mi>u</mi><mo form=prefix stretchy=false>(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>x</mi><mrow><mn>2</mn><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo form=postfix stretchy=false>)</mo></mrow></math></eq> has latency <eq><math><mrow><mn>6</mn><mo>+</mo></mrow><mrow><mo form=prefix stretchy=false>⌈</mo><msub><mi>log</mi><mn>2</mn></msub><mo>⁡</mo><mspace width=0.1667em></mspace><mi>k</mi><mo form=postfix stretchy=false>⌉</mo></mrow></math></eq> as long as there are enough registers; increment <eq><math><mi>k</mi></math></eq> by one for odd-length data. When the input is just one word, <eq><math><mrow><mi>u</mi><mo form=prefix stretchy=false>(</mo><mi>x</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq> has latency <eq><math><mn>5</mn></math></eq>.<p class=next-group><span aria-level=3 class=side-header role=heading><span>Optimizations</span></span>Our next goal is to improve performance of this generic hash by removing some operations or replacing them with faster ones, utilizing patterns observed in the training set.<p>Our main tool is to mix individual words with faster algorithms than multiplication if the words are independent in some fashion. Several smaller-than-<eq><math><mi>N</mi></math></eq> inputs can be merged together with shifting and addition injectively. (On a relevant note, if we need to produce a <eq><math><mn>32</mn></math></eq>-bit hash, merging inputs into <eq><math><mn>64</mn></math></eq>-bit words and then truncating the hash is going to be more efficient than working with <eq><math><mrow><mi>N</mi><mo>=</mo></mrow><mrow><mn>32</mn></mrow></math></eq>.) Multiple uncorrelated <eq><math><mi>N</mi></math></eq>-bit inputs can often be mixed simply with <eq><math><mo lspace=0em rspace=0em>+</mo></math></eq> or <eq><math><mo lspace=0em rspace=0em>⊕︎</mo></math></eq>. Correlated inputs can be “decorrelated” by bit-rotating or byte-swapping.<p>Once a smaller vector <eq><math><mrow><mo form=prefix stretchy=false>(</mo><msub><mi>y</mi><mn>0</mn></msub><mo separator=true>,</mo><mo>…</mo><mo separator=true>,</mo><msub><mi>y</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo form=postfix stretchy=false>)</mo></mrow></math></eq> is obtained such that no two <eq><math><mrow><msub><mi>y</mi><mi>i</mi></msub><mo separator=true>,</mo></mrow><mrow><msub><mi>y</mi><mi>j</mi></msub></mrow></math></eq> can be mixed together cheaply without increasing the collision rate significantly, we hash the vector with the function <eq><math><mi>u</mi></math></eq>.<p>If <eq><math><mrow><mi>k</mi><mo>=</mo></mrow><mrow><mn>1</mn></mrow></math></eq>, we consider extracting entropy from the word directly with a <code>pext</code> instruction, which saves one AND when all <eq><math><msub><mi>n</mi><mi>i</mi></msub></math></eq> are powers of two.<p>We then try to find a word that has enough entropy in the places where we extract <eq><math><msub><mi>h</mi><mi>i</mi></msub></math></eq> from, so that we can avoid hashing it with <eq><math><mi>u</mi></math></eq> and instead directly xor/add it to the result of <eq><math><mi>u</mi></math></eq>. How successful this is depends on how <eq><math><msub><mi>h</mi><mi>i</mi></msub></math></eq> is extracted; bit-rotating or byte-swapping <eq><math><msub><mi>y</mi><mi>i</mi></msub></math></eq> might also be useful here.<p>We then consider optimizing individual <eq><math><mrow><mtext></mtext><mi>mum</mi></mrow></math></eq> calls. For uniform inputs, <eq><math><mrow><mo>⊕︎</mo></mrow><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow></math></eq> can be omitted, saving one or more xors. Alternatively, they can sometimes be reused across invocations, which is a positive, as <eq><math><mn>64</mn></math></eq>-bit constants have to be loaded into registers manually. Finally, when <eq><math><msub><mi>h</mi><mi>i</mi></msub></math></eq> is extracted from the top bits rather than the bottom bits, or if the input is somewhat uniform, <eq><math><mrow><mtext></mtext><mi>mum</mi></mrow></math></eq> can sometimes be replaced with just the low half of the multiplication, which has latency <eq><math><mn>3</mn></math></eq> rather than <eq><math><mn>5</mn></math></eq>. When replacing <eq><math><mrow><mrow><mtext></mtext><mi>num</mi></mrow><mo form=prefix stretchy=false>(</mo><mi>a</mi><mo separator=true>,</mo><mi>x</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq> with <eq><math><mrow><mi>a</mi><mi>x</mi></mrow></math></eq>, we need to use odd <eq><math><mi>a</mi></math></eq>; in fact, it is provable that as long as <eq><math><mrow><mi>k</mi><mo>=</mo></mrow><mrow><mn>1</mn></mrow></math></eq>, this is a safe replacement.<p>Now, if <eq><math><mi>u</mi></math></eq> has an odd number of arguments, we can sometimes cheat by replacing <eq><math><mrow><mrow><mtext></mtext><mi>mum</mi></mrow><mo form=prefix stretchy=false>(</mo><mi>a</mi><mo separator=true>,</mo><mi>x</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq> with <eq><math><mrow><mrow><mtext></mtext><mi>crc32</mi></mrow><mo form=prefix stretchy=false>(</mo><mi>x</mi><mo form=postfix stretchy=false>)</mo></mrow></math></eq>, which performs faster by <eq><math><mn>1</mn></math></eq> or <eq><math><mn>2</mn></math></eq> ticks on x86-64 while still achieving full avalanche. On x86-64, the instruction <code>crc32 a, b</code> computes CRC32 of <eq><math><mrow><mi>a</mi><mo>⊕︎</mo></mrow><mrow><mi>b</mi></mrow></math></eq>, allowing us to save <eq><math><mn>1</mn></math></eq> more tick when <eq><math><mi>x</mi></math></eq> is a xor-mix of several input words. Clearly, CRC32 outputs a <eq><math><mn>32</mn></math></eq>-bit hash, so when extracting entropy from the top half of the output, it needs to be shifted; alternatively, if this is the only summand in <eq><math><mi>u</mi></math></eq>, we can use <eq><math><mn>32</mn></math></eq>-bit arithmetic directly.<p class=next-group><span aria-level=3 class=side-header role=heading><span>Long data</span></span>When hashing longer objects, we can try to find a few individual subwords that have enough entropy and hash them with the above methods.<p>If that fails, we have to hash the byte array directly instead, for which any of your favorite hash algorithms suffice. Note that we don’t necessarily have to choose a “good” hash, just one that leads to few collisions on the training dataset. In order of decreasing performance and increasing collision resistance, we thus try:<ul><li>CRC32<li>The AES-NI implementation of <code>t1ha0</code><li>XXH3<li>MeowHash</ul><p class=next-group><span aria-level=3 class=side-header role=heading><span>Sources</span></span>Several papers contibuted to the approaches described in this article:<ul><li>M. Dietzfelbinger, T. Hagerup, J. Katajainen, M. Penttonen. <a href=https://doi.org/10.1006/jagm.1997.0873>A Reliable Randomized Algorithm for the Closest-Pair Problem</a><li>J. Black, S. Halevi, H. Krawczyk, T. Krovetz, P. Rogaway. <a href=https://www.cs.ucdavis.edu/~rogaway/papers/umac-full.pdf>UMAC: Fast and Secure Message Authentication</a></ul></div></section><footer><div class=viewport-container><h2>Made with my own bare hands (why.)</h2></div></footer><script>window.addEventListener("keydown", e => {
				if (e.key === "Enter") {
					if (e.ctrlKey) {
						window.open("https://github.com/purplesyringa/site/edit/master/blog/tiered-hashing/index.md", "_blank");
					} else if (
						e.target.type === "checkbox"
						&& e.target.parentNode
						&& e.target.parentNode.className === "expansible-code"
					) {
						e.target.click();
					}
				}
			});</script>