<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>purplesyringa's blog</title>
		<link>https://purplesyringa.moe/blog/</link>
		<description>Posts from purplesyringa's blog.</description>
		<copyright>Alisa Sireneva, CC BY</copyright>
		<managingEditor>me@purplesyringa.moe (Alisa Sireneva)</managingEditor>
		<webMaster>me@purplesyringa.moe (Alisa Sireneva)</webMaster>
		<lastBuildDate>Sat, 07 Sep 2024 13:10:54 GMT</lastBuildDate>
		<docs>https://www.rssboard.org/rss-specification</docs>
		<ttl>60</ttl>
		<atom:link href="https://purplesyringa.moe/blog/feed.rss" rel="self" type="application/rss+xml" />
		
			<item>
				<title>WebP: The WebPage compression format</title>
				<link>https://purplesyringa.moe/blog/./webp-the-webpage-compression-format/nojs.html</link>
				<description>I want to provide a smooth experience to my site visitors, so I work on accessibility and ensure it works without JavaScript enabled. I care about page load time because some pages contain large illustrations, so I minify my HTML.
But one thing makes turning my blog light as a feather a pain in the ass.</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				<comments>https://www.reddit.com/r/programming/comments/1fb5pzh/webp_the_webpage_compression_format/</comments>
				<guid>https://purplesyringa.moe/blog/./webp-the-webpage-compression-format/</guid>
				<pubDate>Sat, 07 Sep 2024 00:00:00 GMT</pubDate>
			</item>
		
			<item>
				<title>Division is hard, but it doesn&#39;t have to be</title>
				<link>https://purplesyringa.moe/blog/./division-is-hard-but-it-does-not-have-to-be/</link>
				<description>Developers don’t usually divide numbers all the time, but hashmaps often need to compute remainders modulo a prime. Hashmaps are really common, so fast division is useful.
For instance, rolling hashes might compute u128 % u64 with a fixed divisor. Compilers just drop the ball here:
fn modulo(n: u128) -> u64 {
(n % 0xffffffffffffffc5) as u64
}

modulo:
push rax
mov rdx, -59
xor ecx, ecx
call qword ptr [rip + __umodti3@GOTPCREL]
pop rcx
ret

__umodti3 is a generic long division implementation, and it’s slow and ugly.
I prefer my code the opposite of slow and ugly.</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				<comments>https://www.reddit.com/r/programming/comments/1f0n8sk/division_is_hard_but_it_doesnt_have_to_be/</comments>
				<guid>https://purplesyringa.moe/blog/./division-is-hard-but-it-does-not-have-to-be/</guid>
				<pubDate>Sat, 24 Aug 2024 00:00:00 GMT</pubDate>
			</item>
		
			<item>
				<title>I sped up serde_json strings by 20%</title>
				<link>https://purplesyringa.moe/blog/./i-sped-up-serde-json-strings-by-20-percent/</link>
				<description>I have recently done some performance work and realized that reading about my experience could be entertaining. Teaching to think is just as important as teaching to code, but this is seldom done; I think something I’ve done last month is a great opportunity to draw the curtain a bit.
serde is the Rust framework for serialization and deserialization. Everyone uses it, and it’s the default among the ecosystem. serde_json is the official serde “mixin” for JSON, so when people need to parse stuff, that’s what they use instinctively. There are other libraries for JSON parsing, like simd-json, but serde_json is overwhelmingly used: it has 26916 dependents at the time of this post, compared to only 66 for simd-json.
This makes serde_json a good target (not in a Jia Tan way) for optimization. Chances are, many of those 26916 users would profit from switching to simd-json, but as long as they aren’t doing that, smaller optimizations are better than nothing, and such improvements are reapt across the ecosystem.</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				<comments>https://www.reddit.com/r/rust/comments/1eyxspu/i_sped_up_serde_json_strings_by_20/</comments>
				<guid>https://purplesyringa.moe/blog/./i-sped-up-serde-json-strings-by-20-percent/</guid>
				<pubDate>Tue, 20 Aug 2024 00:00:00 GMT</pubDate>
			</item>
		
			<item>
				<title>The sentinel trick</title>
				<link>https://purplesyringa.moe/blog/./the-sentinel-trick/</link>
				<description>The sentinel trick underlies a data structure with the following requirements:

Read element by index in O ( 1 ) ,
Write element by index in O ( 1 ) ,
Replace all elements with a given value in O ( 1 ) .

It is not a novel technique by any means, but it doesn’t seem on everyone’s lips, so some of you might find it interesting.</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				<comments>https://t.me/alisa_rummages/148</comments>
				<guid>https://purplesyringa.moe/blog/./the-sentinel-trick/</guid>
				<pubDate>Tue, 13 Aug 2024 00:00:00 GMT</pubDate>
			</item>
		
			<item>
				<title>You might want to use panics for error handling</title>
				<link>https://purplesyringa.moe/blog/./you-might-want-to-use-panics-for-error-handling/</link>
				<description>Rust’s approach to error handling comes at a cost. The Result type often doesn’t fit in CPU registers, and callers of fallible functions have to check whether the returned value is Ok or Err. That’s a stack spill, a comparison, a branch, and a lot of error handling code intertwined with the hot path that just shouldn’t be here, which inhibits inlining, the most important optimization of all.
Exceptions and panics make it easy to forget about the occasional error, but they don’t suffer from inefficiency. Throwing an exception unwinds the stack automatically, without any cooperation from the functions except the one that throws the exception and the one that catches it. Wouldn’t it be neat if a mechanism with the performance of panic! and the ergonomics of Result existed?</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				
				<guid>https://purplesyringa.moe/blog/./you-might-want-to-use-panics-for-error-handling/</guid>
				<pubDate>Tue, 13 Aug 2024 00:00:00 GMT</pubDate>
			</item>
		
			<item>
				<title>У base64 есть неподвижная точка</title>
				<link>https://purplesyringa.moe/blog/ru/base64-has-a-fixed-point/</link>
				<description>$ base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 \
| base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 \
| base64 | head -1
Vm0wd2QyUXlVWGxWV0d4V1YwZDRWMVl3WkRSV01WbDNXa1JTVjAxV2JETlhhMUpUVmpBeFYySkVU

$ base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 \
| base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 | base64 \
| base64 | head -1
Vm0wd2QyUXlVWGxWV0d4V1YwZDRWMVl3WkRSV01WbDNXa1JTVjAxV2JETlhhMUpUVmpBeFYySkVU</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				<comments>https://t.me/alisa_rummages/146</comments>
				<guid>https://purplesyringa.moe/blog/ru/base64-has-a-fixed-point/</guid>
				<pubDate>Sat, 03 Aug 2024 00:00:00 GMT</pubDate>
			</item>
		
			<item>
				<title>I thought I was smart enough to play with fire</title>
				<link>https://purplesyringa.moe/blog/./i-thought-i-was-smart-enough-to-play-with-fire/</link>
				<description>blazingio cuts corners by design. It keeps the constant factor small and uses long forgotten algorithms people used before processors supported SIMD and integer division. But another limitation made this task much harder.
Size.
Professional libraries start exceeding the Codeforces limit of 64 KiB really fast. Code minification barely helps, and neither does resorting to ugly code. So I cut a corner I don’t typically cut.
Undefined Behavior.
These two words make a seasoned programmer shudder. But sidestepping UB increases code size so much the library can hardly be used on CF. So I took a gamble. I meticulously scanned every instance of UB I used intentionally and made sure the compiler had absolutely no reason to miscompile it. I wrote excessive tests and run them on CI on all architecture and OS combinations I could think of. I released the library without so much as a flaw. It worked like clockwork.
And then, 3 months later, I updated README, and all hell broke loose.</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				<comments>https://codeforces.com/blog/entry/130661</comments>
				<guid>https://purplesyringa.moe/blog/./i-thought-i-was-smart-enough-to-play-with-fire/</guid>
				<pubDate>Thu, 20 Jun 2024 00:00:00 GMT</pubDate>
			</item>
		
			<item>
				<title>Recovering garbled Bitcoin addresses</title>
				<link>https://purplesyringa.moe/blog/./recovering-garbled-bitcoin-addresses/</link>
				<description>ZeroNet is a decentralized network that enables dynamic sites, such as blogs and forums, unlike popular content-addressed storage networks that came later. Sites aren’t addressed by immutable hashes; instead, site updates are signed by Bitcoin addresses.
A moot point is that Bitcoin addresses are case-sensitive, and people are used to addresses being case-insensitive. Mistakes happen, and sometimes the only trail you have is a lower-cased address, like 1lbcfr7sahtd9cgdqo3htmtkv8lk4znx71.
Losing valuable information is a bad thing when you’re an archivist. Have we really lost access to the site if we only know the lower-cased address? Can we recover the original address somehow?</description>
				<author>me@purplesyringa.moe (Alisa Sireneva)</author>
				<comments>https://t.me/alisa_rummages/111</comments>
				<guid>https://purplesyringa.moe/blog/./recovering-garbled-bitcoin-addresses/</guid>
				<pubDate>Tue, 23 Apr 2024 00:00:00 GMT</pubDate>
			</item>
		
	</channel>
</rss>